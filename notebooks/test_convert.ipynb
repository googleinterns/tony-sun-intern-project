{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter/tony-sun-intern-project/neutral_generation')\n",
    "from constants import *\n",
    "from smart_convert import convert\n",
    "from smart_convert import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1961, their single \"Water Boy\" reached No. 40 on the Billboard Hot 100 and stayed on the chart for 14 weeks.\n",
      "\n",
      "CPU times: user 304 ms, sys: 28 ms, total: 332 ms\n",
      "Wall time: 602 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21.163183212280273"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sent = convert('In 1961, her single \"Water Boy\" reached No. 40 on the Billboard Hot 100 and stayed on the chart for 14 weeks.\\n')\n",
    "print(sent)\n",
    "score(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1961, theirs single \"Water Boy\" reached No. 40 on the Billboard Hot 100 and stayed on the chart for 14 weeks.\n",
      "\n",
      "CPU times: user 220 ms, sys: 32 ms, total: 252 ms\n",
      "Wall time: 28.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35.34559631347656"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sent = convert('In 1961, his single \"Water Boy\" reached No. 40 on the Billboard Hot 100 and stayed on the chart for 14 weeks.\\n')\n",
    "print(sent)\n",
    "score(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.88 s, sys: 492 ms, total: 6.38 s\n",
      "Wall time: 2.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from fairseq.models.transformer import TransformerModel\n",
    "gn = TransformerModel.from_pretrained(\n",
    "  '/home/sunto/fairseq/logs_checkpoints/old_files/transformer_checkpoints_0817',\n",
    "  checkpoint_file='checkpoint_best.pt',\n",
    "  data_name_or_path='/home/sunto/fairseq/data-bin/old_files/gn_wiki_data_updated_all_combined_tokenized',\n",
    "  bpe='subword_nmt',\n",
    "  bpe_codes='/home/sunto/fairseq/examples/translation/old_datasets/gn_wiki_data_updated_all_combined/code'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.74 s, sys: 1.1 s, total: 6.84 s\n",
      "Wall time: 2.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from fairseq.models.transformer import TransformerModel\n",
    "gn = TransformerModel.from_pretrained(\n",
    "  '/home/sunto/fairseq/logs_checkpoints/new_datasets/sa_nt_10_3',\n",
    "  checkpoint_file='checkpoint_best.pt',\n",
    "  data_name_or_path='/home/sunto/fairseq/data-bin/new_datasets/sa_nt_10_3',\n",
    "  bpe='subword_nmt',\n",
    "  bpe_codes='/home/sunto/fairseq/examples/translation/new_datasets/sa_nt_10_3/code'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'They sing in the shower and dance in the dark.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gn.translate('She sings in the shower and dances in the dark.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do they know what happened to their friend?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gn.translate('Do they know what happened to their friend?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = 'gendered'\n",
    "\n",
    "with open(f'/home/jupyter/tony-sun-intern-project/evaluation/{test_set}/source.txt', 'r') as f:\n",
    "    source = f.readlines()\n",
    "    \n",
    "with open(f'/home/jupyter/tony-sun-intern-project/evaluation/{test_set}/target.txt', 'r') as f:\n",
    "    target = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'model_simple_augmentation'\n",
    "with open(f'/home/jupyter/tony-sun-intern-project/evaluation/{test_set}/generations/{model}/generation.txt', 'r') as f:\n",
    "    generation = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/jupyter/tony-sun-intern-project/evaluation')\n",
    "from evaluate_generation import get_metrics, get_bleu, get_word_error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.77089687297988"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bleu(generation=generation, annotation=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.205520037423982"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_error_rate(generation=generation, annotation=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('tony-sun-intern-project/neutral_generation')\n",
    "from smart_convert import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.155597686767578"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score('Do they know what happened to their friend?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.005859375"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score('Do they know what happened to them friend?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_convert import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do they know what happened to their friend?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert(\"Does she know what happened to her friend?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tony-sun-intern-project/evaluation/gendered_test_set/source.txt', 'r') as f:\n",
    "    source = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tony-sun-intern-project/evaluation/gendered_test_set/generations/model_sa_nt_10_3/generation.txt', 'r') as f:\n",
    "    model = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tony-sun-intern-project/evaluation/gendered_test_set/generations/convert/generation.txt', 'r') as f:\n",
    "    smart_convert = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tony-sun-intern-project/evaluation/gendered_test_set/generations/old_convert_1/generation.txt', 'r') as f:\n",
    "    old_convert = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'They sing in the shower and dances in the dark.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert('She sings in the shower and dances in the dark.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    if source[i] == model[i] and source[i] != smart_convert[i]:\n",
    "        print('algo           : ', convert[i])\n",
    "        print('model (correct): ', model[i])        \n",
    "else:\n",
    "    print('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't you shut up and let her talk?\n",
      "\n",
      "algo (correct):  Why don't you shut up and let her talk?\n",
      "\n",
      "model         :  Why don't you shut up and let them talk?\n",
      "\n",
      "---\n",
      "Loo-hoo-ser-her.\n",
      "\n",
      "algo (correct):  Loo-hoo-ser-her.\n",
      "\n",
      "model         :  Loo-hoo-ser-them.\n",
      "\n",
      "---\n",
      "The other 2 ask \"How'd you do that?\"She says: \"Well, I followed some tracks,and BOOM, I got a rabbit.\"\n",
      "\n",
      "algo (correct):  The other 2 ask \"How'd you do that?\"She says: \"Well, I followed some tracks,and BOOM, I got a rabbit.\"\n",
      "\n",
      "model         :  The other 2 ask \"How'd you do that?\"They say: \"Well, I followed some tracks,and BOOM, I got a rabbit.\"\n",
      "\n",
      "---\n",
      "Should I pack for the ocean, or should I pack for the mountains?\"He says, \"I don't care.\n",
      "\n",
      "algo (correct):  Should I pack for the ocean, or should I pack for the mountains?\"He says, \"I don't care.\n",
      "\n",
      "model         :  Should I pack for the ocean, or should I pack for the mountains?\"They say, \"I don't care.\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    if source[i] == smart_convert[i] and source[i] != model[i]:\n",
    "        print(source[i])\n",
    "        print('algo (correct): ', smart_convert[i])\n",
    "        print('model         : ', model[i])   \n",
    "        print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, them!'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert('Oh, him!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh, it's them!\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert(\"Oh, it's him!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

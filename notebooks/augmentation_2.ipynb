{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wikipedia_training/simple_augmentation/simple_augmentation.source', 'r') as f:\n",
    "    source_lines = f.readlines()\n",
    "\n",
    "with open('wikipedia_training/simple_augmentation/simple_augmentation.target', 'r') as f:\n",
    "    target_lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000000, 30000000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_lines), len(target_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Prior, he served as a reporter in the style department, where he wrote in the dining section since September 1997. From October 1991 until September 1997 he worked as a reporter on the cultural desk where he covered independent film, visual art, and books.\\n',\n",
       "  'Prior, she served as a reporter in the style department, where she wrote in the dining section since September 1997. From October 1991 until September 1997 she worked as a reporter on the cultural desk where she covered independent film, visual art, and books.\\n'],\n",
       " ['Prior, they served as a reporter in the style department, where they wrote in the dining section since September 1997. From October 1991 until September 1997 they worked as a reporter on the cultural desk where they covered independent film, visual art, and books.\\n',\n",
       "  'Prior, they served as a reporter in the style department, where they wrote in the dining section since September 1997. From October 1991 until September 1997 they worked as a reporter on the cultural desk where they covered independent film, visual art, and books.\\n'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_lines[100:102], target_lines[100:102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacremoses import MosesTokenizer\n",
    "mt = MosesTokenizer(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_list(sentences):\n",
    "    tokenized_list = list()\n",
    "    \n",
    "    for sent in sentences:\n",
    "        tokenized = mt.tokenize(sent, return_str=True)\n",
    "        tokenized_list.append(tokenized)\n",
    "    \n",
    "    return tokenized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 49min 39s, sys: 2min 39s, total: 2h 52min 18s\n",
      "Wall time: 2h 52min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "source = tokenize_list(sentences=source_lines)\n",
    "target = tokenize_list(sentences=target_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000000, 30000000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source), len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wikipedia_training/simple_augmentation_tokenized/simple_augmentation_tokenized.source', 'w') as f:\n",
    "    for sent in source:\n",
    "        f.write(sent)\n",
    "        f.write('\\n')\n",
    "\n",
    "with open('wikipedia_training/simple_augmentation_tokenized/simple_augmentation_tokenized.target', 'w') as f:\n",
    "    for sent in target:\n",
    "        f.write(sent)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
